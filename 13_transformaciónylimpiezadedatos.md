# ğŸ”µ **Tema 6.5.3 â€“ TransformaciÃ³n y Limpieza de Datos en Big Data**

La **transformaciÃ³n y limpieza de datos** es una fase importante en el ciclo de vida del Big Data. Los datos reales, especialmente en entornos empresariales, suelen estar incompletos, inconsistentes o en formatos poco manejables, lo que requiere tÃ©cnicas avanzadas para mejorar su calidad y adecuarlos a su uso analÃ­tico.

En esta secciÃ³n cubriremos en profundidad:

âœ… IntroducciÃ³n a la transformaciÃ³n y limpieza de datos  
âœ… Operaciones de limpieza (datos faltantes, inconsistencias, duplicados)  
âœ… Transformaciones avanzadas (joins, filtrado, agregaciones)  
âœ… Uso de herramientas clave: `sparklyr`, `dplyr` y pipelines en Spark  
âœ… Ejemplos prÃ¡cticos con el dataset de **NYC Taxi Trips**  
âœ… Ejercicios prÃ¡cticos para que los alumnos fortalezcan su comprensiÃ³n  

---

## ğŸ”¹ **1. IntroducciÃ³n a la TransformaciÃ³n y Limpieza de Datos**

El **proceso de transformaciÃ³n** se centra en convertir los datos brutos en un formato limpio, coherente y estructurado, listo para su anÃ¡lisis o modelado predictivo.  

El proceso de **limpieza de datos** se enfoca en resolver problemas comunes como:

âœ… Valores faltantes  
âœ… Inconsistencias en los datos  
âœ… Duplicados  
âœ… Valores atÃ­picos (outliers)  
âœ… Formatos incorrectos  

### ğŸš¨ **Â¿Por quÃ© es importante limpiar los datos en Big Data?**

En proyectos de Big Data, la calidad de los datos es clave. Trabajar con datos incorrectos puede generar:

âŒ Predicciones inexactas  
âŒ Informes errÃ³neos que dificulten la toma de decisiones  
âŒ Desperdicio de recursos computacionales  

El dataset de **NYC Taxi Trips**, por ejemplo, puede contener, entre otros:

- **Registros incompletos** (sin fecha de viaje o con coordenadas GPS incorrectas).  
- **Tarifas negativas** (errores en la captura de datos).  
- **Duplicados** (registros duplicados debido a errores en el sistema de recopilaciÃ³n).  

---

## ğŸ”¹ **2. Operaciones de Limpieza de Datos**

En esta secciÃ³n abordaremos tÃ©cnicas clave de limpieza usando R y Spark.

### ğŸŸ  **2.1. DetecciÃ³n y GestiÃ³n de Valores Faltantes**
Los datos faltantes pueden deberse a errores en el sistema de registro, sensores defectuosos o fallos en el envÃ­o de datos.

### ğŸ” **Identificar valores faltantes**
```r
# Identificar valores faltantes en el dataset
taxi_nyc %>%
  summarise_all(~ sum(is.na(.))) %>%
  collect()
```

### ğŸ”§ **GestiÃ³n de datos faltantes**
- **EliminaciÃ³n:** Para datos irrelevantes o registros con pocos valores.  
- **ImputaciÃ³n:** Rellenar los valores faltantes con la media, mediana o un valor calculado.  

```r
# Eliminar registros con datos faltantes
taxi_nyc_clean <- taxi_nyc %>%
  filter(!is.na(fare_amount) & !is.na(pickup_datetime))

# Imputar valores faltantes (ejemplo: rellenar 'passenger_count' con la media)
taxi_nyc_clean <- taxi_nyc_clean %>%
  mutate(passenger_count = ifelse(is.na(passenger_count), mean(passenger_count, na.rm = TRUE), passenger_count))
```

---

### ğŸŸ  **2.2. CorrecciÃ³n de Inconsistencias**
Los datos inconsistentes suelen ocurrir debido a errores humanos, problemas tÃ©cnicos o diferentes formatos de entrada.

### ğŸ” **DetecciÃ³n de inconsistencias**
Por ejemplo, una **tarifa negativa** en un viaje es un error evidente.

```r
# Detectar registros con tarifas negativas
taxi_nyc %>%
  filter(fare_amount < 0) %>%
  count()
```

### ğŸ”§ **CorrecciÃ³n de inconsistencias**
- Eliminar registros con valores claramente errÃ³neos.  
- Sustituir valores incorrectos con cÃ¡lculos estimados.  

```r
# Eliminar registros con tarifas negativas
taxi_nyc_clean <- taxi_nyc %>%
  filter(fare_amount >= 0)
```

---

### ğŸŸ  **2.3. DetecciÃ³n y EliminaciÃ³n de Duplicados**
Los datos duplicados suelen ocurrir por errores en la ingesta o procesos de carga.

### ğŸ” **DetecciÃ³n de duplicados**
```r
# Detectar registros duplicados
taxi_nyc %>%
  group_by(pickup_datetime, dropoff_datetime, trip_distance) %>%
  summarise(total_registros = n()) %>%
  filter(total_registros > 1)
```

### ğŸ”§ **EliminaciÃ³n de duplicados**
```r
# Eliminar duplicados
taxi_nyc_clean <- taxi_nyc %>%
  distinct(pickup_datetime, dropoff_datetime, trip_distance, .keep_all = TRUE)
```

---

## ğŸ”¹ **3. Transformaciones Avanzadas**

Las transformaciones avanzadas permiten estructurar y enriquecer los datos para obtener informaciÃ³n mÃ¡s valiosa.

### ğŸŸ  **3.1. Filtrado de Datos**
El filtrado selecciona Ãºnicamente los registros que cumplen ciertos criterios.

**Ejemplo:** Filtrar viajes que recorrieron mÃ¡s de 10 millas.

```r
taxi_nyc_clean <- taxi_nyc %>%
  filter(trip_distance > 10)
```

---

### ğŸŸ  **3.2. Joins (Uniones)**
Las uniones permiten combinar tablas basÃ¡ndose en una clave comÃºn.

**Ejemplo:** Unir el dataset de taxis con una tabla que contenga zonas de recogida.

```r
zonas <- data.frame(
  zone_id = c(1, 2, 3),
  zone_name = c("Manhattan", "Brooklyn", "Queens")
)

taxi_nyc_zones <- taxi_nyc %>%
  left_join(zonas, by = c("PULocationID" = "zone_id"))
```

---

### ğŸŸ  **3.3. Agregaciones**
Las agregaciones resumen la informaciÃ³n, calculando mÃ©tricas clave.

**Ejemplo:** Calcular la tarifa promedio por dÃ­a.

```r
taxi_nyc_clean %>%
  group_by(date = as.Date(pickup_datetime)) %>%
  summarise(
    tarifa_promedio = mean(fare_amount, na.rm = TRUE)
  ) %>%
  arrange(desc(tarifa_promedio)) %>%
  collect()
```

---

## ğŸ”¹ **4. Uso de Pipelines en Spark**

Los **pipelines** permiten encadenar mÃºltiples transformaciones y simplificar el flujo de trabajo en Spark.

### ğŸ” **Pipeline bÃ¡sico con `sparklyr`**
```r
taxi_pipeline <- taxi_nyc %>%
  filter(fare_amount > 0) %>%
  mutate(
    total_fare = fare_amount + tip_amount,
    trip_day = weekdays(pickup_datetime)
  ) %>%
  group_by(trip_day) %>%
  summarise(total_viajes = n())
```

---

## ğŸ”¹ **5. Ejercicios PrÃ¡cticos**

### ğŸŸ© **Ejercicio 1 â€“ Limpieza completa del dataset**
**Objetivo:**  
- Cargar el dataset NYC Taxis en formato **Parquet**.  
- Eliminar registros con tarifas negativas.  
- Eliminar registros duplicados.  
- Imputar los valores faltantes en `passenger_count` usando la media (opcional).  

**CÃ³digo inicial:**

```r

```

---

### ğŸŸ© **Ejercicio 2 â€“ AnÃ¡lisis de propinas por dÃ­a de la semana**
**Objetivo:**  
- Cargar el dataset NYC Taxis.  
- Calcular la propina media (`tip_amount`) para cada dÃ­a de la semana.  
- Determinar quÃ© dÃ­a de la semana se deja mayor propina promedio.  

**CÃ³digo inicial:**

```r

```
